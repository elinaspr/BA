{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb587fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4934299",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "fourgram_measures = nltk.collocations.QuadgramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d726af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing already created output-file.txt (review AppliedFunctions), \n",
    "## which contains all text filed labelled as beginner-level\n",
    "with open('output-leicht.txt', encoding = 'utf-8') as text:\n",
    "    textoutput = text.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79e10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make textoutput processable for CollocationFinder functions\n",
    "text = nltk.wordpunct_tokenize(textoutput)\n",
    "##Filter out punctuation marks etc\n",
    "tokens = [word for word in text if word.isalpha()]\n",
    "\n",
    "## Create finders\n",
    "finderb = BigramCollocationFinder.from_words(tokens)\n",
    "findert = TrigramCollocationFinder.from_words(tokens)\n",
    "finderf = QuadgramCollocationFinder.from_words(tokens)\n",
    "\n",
    "## optional: filter, so that only those n-grams remain that appear 2+ times\n",
    "finderb.apply_freq_filter(2)\n",
    "findert.apply_freq_filter(2)\n",
    "finderf.apply_freq_filter(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512a5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Named Entity Recognition (NER) preparation\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "# NLP model is applied to processable part of textoutput (maximal length is 1000000)\n",
    "doc = nlp(textoutput[:1000000])\n",
    "## if len(textoutput) > 1000000 the nlp function has to be applied to its split parts; \n",
    "# in our case the length was 1051064, thus nlp was applied twice\n",
    "doc2 = nlp(textoutput[1000000:])\n",
    "\n",
    "## collect all named entities that are a location or person in one set\n",
    "entities = [tuple(nltk.wordpunct_tokenize(ent.text)) for ent in doc.ents if ent.label_ in {'PER', 'LOC'}]\n",
    "# since len(textoutput) > 1000000, scanning had to be applied on both doc and doc2 and the collected entities combined\n",
    "entities = entities + [tuple(nltk.wordpunct_tokenize(ent.text)) for ent in doc2.ents if ent.label_ in {'PER', 'LOC'}]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22fa2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COLLECT TOP ENTRIES\n",
    "\n",
    "#### Functions that return top specified ngrams for three different association measures  \n",
    "#### with their respective measure values and amount of occurences\n",
    "#### and attempts to filter out entries with Named Person/Location entities or 'gibt'\n",
    "#### to make other collocations visible/ list shorter \n",
    "#### -> doesn't filter out everything, to review limitations use AppliedFunctions.ipynb\n",
    "\n",
    "### The three association measures are Pointwise Mutual Information, Likelihood Ratio and Frequency\n",
    "\n",
    "### PMI: degree of association between words by comparing observed co-occurrence frequency with \n",
    "### expected co-occurrence frequency if they were independent \n",
    "\n",
    "### Likelihood Ratio: statistical measure indicating the strength of association between words\n",
    "## further details: https://stackoverflow.com/questions/21165702/nltk-collocations-for-specific-words\n",
    "\n",
    "### Normalized frequency: calculates and normalizes the raw frequency of an ngram, thus the appearance probability\n",
    "#### Functions for different association measures, all of which return lists with ngrams, measure values and amount of occurences\n",
    "\n",
    "\n",
    "def toppmi(ngram,n):\n",
    "    \"\"\"\n",
    "    toppmi collects top ngrams when measured by pointwise mutual information (PMI), \n",
    "    with their respective PMI values and amount of occurences \n",
    "    and then filters out entries with Named Entities or 'gibt'\n",
    "    \n",
    "    :ngram: string specifying whether to return top bigrams, trigrams or fourgrams\n",
    "    :n: amount of top entries function initially looks at \n",
    "    :return: list of three-component-tuples \n",
    "    \"\"\"\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.pmi, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in bigram or bigram in entities):\n",
    "                pmi = finderb.score_ngram(bigram_measures.pmi, bigram[0], bigram[1])\n",
    "                rf = finderb.ngram_fd[bigram]\n",
    "                topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.pmi, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not ('gibt' in trigram or trigram in entities):\n",
    "                pmi = findert.score_ngram(trigram_measures.pmi, trigram[0], trigram[1], trigram[2])\n",
    "                rf = findert.ngram_fd[trigram]\n",
    "                topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.pmi, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in fourgram or fourgram in entities):\n",
    "                pmi = finderf.score_ngram(fourgram_measures.pmi, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                rf = finderf.ngram_fd[fourgram]\n",
    "                topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "\n",
    "def toplikelihood(ngram, n):\n",
    "    \"\"\"\n",
    "    toplikelihood collects top ngrams when measured by Likelihood Ratio, \n",
    "    with their respective Likelihood Ratio values and amount of occurences \n",
    "    and then filters out entries with Named Entities and 'gibt'\n",
    "    \n",
    "    :ngram: string specifying whether to return top bigrams, trigrams or fourgrams\n",
    "    :n: amount of top entries function initially looks at \n",
    "    :return: list of three-component-tuples \n",
    "    \"\"\"\n",
    "    \n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in bigram or bigram in entities):\n",
    "                pmi = finderb.score_ngram(bigram_measures.likelihood_ratio, bigram[0], bigram[1])\n",
    "                rf = finderb.ngram_fd[bigram]\n",
    "                topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in trigram or trigram in entities):\n",
    "                pmi = findert.score_ngram(trigram_measures.likelihood_ratio, trigram[0], trigram[1], trigram[2])\n",
    "                rf = findert.ngram_fd[trigram]\n",
    "                topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in fourgram or fourgram in entities):\n",
    "                pmi = finderf.score_ngram(fourgram_measures.likelihood_ratio, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                rf = finderf.ngram_fd[fourgram]\n",
    "                topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "def topfreq(ngram, n):\n",
    "    \"\"\"\n",
    "    topfreq collects top ngrams when measured by Frequency, \n",
    "    with their respective Frequency values and amount of occurences \n",
    "    and then filters out entries with Named Entities and 'gibt'\n",
    "    \n",
    "    :ngram: string specifying whether to return top bigrams, trigrams or fourgrams\n",
    "    :n: amount of top entries function initially looks at \n",
    "    :return: list of three-component-tuples \n",
    "    \"\"\"\n",
    "    \n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.score_ngrams(bigram_measures.raw_freq)[:n]:\n",
    "        ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in bigram or bigram in entities):\n",
    "                rf = finderb.ngram_fd[bigram[0]]\n",
    "                topn.append(bigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.score_ngrams(trigram_measures.raw_freq)[:n]:\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in trigram or trigram in entities):\n",
    "                rf = findert.ngram_fd[trigram[0]]\n",
    "                topn.append(trigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.score_ngrams(fourgram_measures.raw_freq)[:n]:\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not(('gibt' in fourgram)  or (fourgram in entities)):\n",
    "                rf = finderf.ngram_fd[fourgram[0]]\n",
    "                topn.append(fourgram + (rf,))\n",
    "                \n",
    "    return topn\n",
    "\n",
    "\n",
    "\n",
    "def topnsummary(ngram, n):\n",
    "    \"\"\"\n",
    "    topnsummary applies toppmi, toplikelihood and topfreq \n",
    "    \n",
    "    :ngram: string specifying whether to return top bigrams, trigrams or fourgrams\n",
    "    :n: amount of top entries function initially looks at \n",
    "    :return: text file called \"top[n][ngram]s.txt\" with top entries listed beneath each other, \n",
    "    amount of included entries in final document != n, \n",
    "    since the entries with 'gibt' and named entities are partly filtered out\n",
    "    \"\"\"\n",
    "    with open('top' + str(n) + str(ngram) + 's.txt', 'w', encoding ='utf-8') as output_file:\n",
    "        output_file.write(\"Top \" + str(n) + \" values\\n\\nPMI:\\n\")\n",
    "        for i in toppmi(ngram, n): output_file.write(str(i) + \"\\n\")\n",
    "        output_file.write(\"\\n\\nLikelihoodratio:\\n\") \n",
    "        for i in toplikelihood(ngram, n): output_file.write(str(i) + \"\\n\")                  \n",
    "        output_file.write(\"\\n\\n Top values Frequency:\\n\")\n",
    "        for i in topfreq(ngram, n): output_file.write(str(i) + \"\\n\")\n",
    "                          \n",
    "### Exact amount\n",
    "def printsummary(ngram, n):\n",
    "    \"\"\"\n",
    "    printsummary counts length of output list of functions toppmi, toplikelihood\n",
    "    and topfreq applied on same parameters\n",
    "    \n",
    "    :ngram: string specifying whether to return top bigrams, trigrams or fourgrams\n",
    "    :n: amount of top entries function initially looks at \n",
    "    :return: print of output length \n",
    "    \"\"\"\n",
    "    print(\"Top \" + str(n) + ngram + \" values gibt and named entities filtered out \\n\\nPMI:\\n\")\n",
    "    print(str(len(toppmi(ngram, n))) + \"\\n\")\n",
    "    print(\"Likelihoodratio:\\n\") \n",
    "    print(str(len(toplikelihood(ngram, n))) + \"\\n\")           \n",
    "    print(\"Frequency:\\n\")         \n",
    "    print(str(len(topfreq(ngram, n))) + \"\\n\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fcca92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Produce the files with the top 200 ngrams:\n",
    "topnsummary(\"bigram\", 200)\n",
    "topnsummary(\"trigram\", 200)\n",
    "topnsummary(\"fourgram\", 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
