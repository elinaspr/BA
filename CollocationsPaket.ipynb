{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb587fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d66f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4934299",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "fourgram_measures = nltk.collocations.QuadgramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d726af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing output-file.txt which contains all text filed labelled as beginner-level\n",
    "with open('output-leicht.txt', encoding = 'utf-8') as text:\n",
    "    textoutput = text.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79e10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make textoutput processable for CollocationFinder functions\n",
    "text = nltk.wordpunct_tokenize(textoutput)\n",
    "##Filter out punctuation marks etc\n",
    "tokens = [word for word in text if word.isalpha()]\n",
    "\n",
    "## Create finders\n",
    "finderb = BigramCollocationFinder.from_words(tokens)\n",
    "findert = TrigramCollocationFinder.from_words(tokens)\n",
    "finderf = QuadgramCollocationFinder.from_words(tokens)\n",
    "\n",
    "## optional: filter, so that only those n-grams remain that appear 2+ times\n",
    "finderb.apply_freq_filter(2)\n",
    "findert.apply_freq_filter(2)\n",
    "finderf.apply_freq_filter(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512a5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Named Entity Recognition (NER) preparation\n",
    "import spacy\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "# NLP model is applied to processable part of textoutput (maximal length is 1000000)\n",
    "doc = nlp(textoutput[:1000000])\n",
    "## if len(textoutput) > 1000000 the nlp function has to be applied to its split parts; \n",
    "# in our case the length was 1051064, thus nlp was applied twice\n",
    "doc2 = nlp(textoutput[1000000:])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02375e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect all named entities that are a location or person in one set\n",
    "entities = [tuple(nltk.wordpunct_tokenize(ent.text)) for ent in doc.ents if ent.label_ in {'PER', 'LOC'}]\n",
    "# since len(textoutput) > 1000000, scanning had to be applied on both doc and doc2 and the collected entities combined\n",
    "entities = entities + [tuple(nltk.wordpunct_tokenize(ent.text)) for ent in doc2.ents if ent.label_ in {'PER', 'LOC'}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22fa2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions for different association measures, all of which return lists with ngrams, measure values and amount of occurences\n",
    "\n",
    "#### Attempt to filter out collocations with 'gibt' and named entities, \n",
    "## to make other collocations visible/ list shorter -> doesn't filter out all 'gibt' but some of them\n",
    "\n",
    "\n",
    "### PMI: degree of association between words by comparing observed co-occurrence frequency with \n",
    "### expected co-occurrence frequency if they were independent -> less relevant\n",
    "## for a specified ngram-type, return the top n n-grams concerning its PMI value\n",
    "def toppmi(ngram,n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.pmi, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in bigram or bigram in entities):\n",
    "                pmi = finderb.score_ngram(bigram_measures.pmi, bigram[0], bigram[1])\n",
    "                rf = finderb.ngram_fd[bigram]\n",
    "                topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.pmi, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not ('gibt' in trigram or trigram in entities):\n",
    "                pmi = findert.score_ngram(trigram_measures.pmi, trigram[0], trigram[1], trigram[2])\n",
    "                rf = findert.ngram_fd[trigram]\n",
    "                topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.pmi, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in fourgram or fourgram in entities):\n",
    "                pmi = finderf.score_ngram(fourgram_measures.pmi, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                rf = finderf.ngram_fd[fourgram]\n",
    "                topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "### Likelihood: 10 N-grams with highest likelihood (=statistical measure indicating the strength of association between words)\n",
    "## for a specified ngram-type, return the top n n-grams concerning its likelihood ratio\n",
    "## further details: https://stackoverflow.com/questions/21165702/nltk-collocations-for-specific-words\n",
    "def toplikelihood(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in bigram or bigram in entities):\n",
    "                pmi = finderb.score_ngram(bigram_measures.likelihood_ratio, bigram[0], bigram[1])\n",
    "                rf = finderb.ngram_fd[bigram]\n",
    "                topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in trigram or trigram in entities):\n",
    "                pmi = findert.score_ngram(trigram_measures.likelihood_ratio, trigram[0], trigram[1], trigram[2])\n",
    "                rf = findert.ngram_fd[trigram]\n",
    "                topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in fourgram or fourgram in entities):\n",
    "                pmi = finderf.score_ngram(fourgram_measures.likelihood_ratio, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                rf = finderf.ngram_fd[fourgram]\n",
    "                topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "  \n",
    "\n",
    "### Normalized frequency: calculates and normalizes the raw frequency of an ngram, thus the appearance probability, \n",
    "## sorted first by frequency and second alphabetically [(tuple, rf value, frequency), ...]\n",
    "def topfreq(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.score_ngrams(bigram_measures.raw_freq)[:n]:\n",
    "        ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in bigram or bigram in entities):\n",
    "                rf = finderb.ngram_fd[bigram[0]]\n",
    "                topn.append(bigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.score_ngrams(trigram_measures.raw_freq)[:n]:\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not('gibt' in trigram or trigram in entities):\n",
    "                rf = findert.ngram_fd[trigram[0]]\n",
    "                topn.append(trigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.score_ngrams(fourgram_measures.raw_freq)[:n]:\n",
    "            ## entries with 'gibt' and named entities are not included\n",
    "            if not(('gibt' in fourgram)  or (fourgram in entities)):\n",
    "                rf = finderf.ngram_fd[fourgram[0]]\n",
    "                topn.append(fourgram + (rf,))\n",
    "                \n",
    "    return topn\n",
    "\n",
    "\n",
    "### For given ngram: creates new file based on top n entries according to each measure value, \n",
    "### writes them down, listed beneath each other, in new text file called \"top[n][ngram]s.txt\"\n",
    "### Important: amount of included entries in final document != n, \n",
    "### since the entries with 'gibt' and named entities are counted but not written down.\n",
    "\n",
    "def topnsummary(ngram, n):\n",
    "    with open('top' + str(n) + str(ngram) + 's.txt', 'w', encoding ='utf-8') as output_file:\n",
    "        output_file.write(\"Top \" + str(n) + \" values\\n\\nPMI:\\n\")\n",
    "        for i in toppmi(ngram, n): output_file.write(str(i) + \"\\n\")\n",
    "        output_file.write(\"\\n\\nLikelihoodratio:\\n\") \n",
    "        for i in toplikelihood(ngram, n): output_file.write(str(i) + \"\\n\")                  \n",
    "        output_file.write(\"\\n\\n Top values Frequency:\\n\")\n",
    "        for i in topfreq(ngram, n): output_file.write(str(i) + \"\\n\")\n",
    "                          \n",
    "### Exact amount, for result of running  with n = 200: view cell no 18.\n",
    "def printsummary(ngram, n):\n",
    "    print(\"Top \" + str(n) + ngram + \" values gibt and named entities filtered out \\n\\nPMI:\\n\")\n",
    "    print(str(len(toppmi(ngram, n))) + \"\\n\")\n",
    "    print(\"Likelihoodratio:\\n\") \n",
    "    print(str(len(toplikelihood(ngram, n))) + \"\\n\")           \n",
    "    print(\"Frequency:\\n\")         \n",
    "    print(str(len(topfreq(ngram, n))) + \"\\n\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fcca92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Produce the files with the top 200 ngrams:\n",
    "topnsummary(\"bigram\", 200)\n",
    "topnsummary(\"trigram\", 200)\n",
    "topnsummary(\"fourgram\", 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
