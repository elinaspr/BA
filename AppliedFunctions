{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all text files saved in texts.zip, and merge them into one big file\n",
    "\n",
    "## important: make sure that all files in texts.zip are not empty, in our case it meant deleting the following files: \n",
    "# Deutsch perfekt 12_2018, 12_2019, and all Deutsch perfekt starting from 2011, as they were all empty\n",
    "\n",
    "# importing required modules \n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "## Loop to open all text files in the texts.zip and merge them into one final file output-leicht.txt\n",
    "with open('output-leicht.txt', 'w', encoding ='utf-8') as output_file:\n",
    "    with ZipFile(\"texts.zip\", \"r\") as z:\n",
    "         # Iterate through each folder in the zip file\n",
    "        z.extractall()\n",
    "        # Iterate through each file in the zip\n",
    "        for file in z.namelist(): \n",
    "            # append the file content\n",
    "            with open(file, 'r', encoding ='utf-8') as f:\n",
    "                ## Merge only the easy texts (A1 and A2)\n",
    "                if \"leicht\" in f.name:\n",
    "                    output_file.write(f.read())\n",
    "             \n",
    "##\n",
    "## Import final file as textoutput\n",
    "with open('output-leicht.txt', encoding = 'utf-8') as text:\n",
    "    textoutput = text.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS CELL IS SIMPLY FOR THE SAKE OF ESTIMATING THE CODE'S LIMITATIONS, NO NEED TO RUN IT\n",
    "### For result of running it with n = 200: view cell no 18.\n",
    "\n",
    "#### Functions for different association measures, all of which return lists with ngrams, measure values and amount of occurences\n",
    "\n",
    "#### To estimate limitation of code: Version without filtering out of 'gibt' and Named Entities\n",
    "\n",
    "### For result of running it with n = 200: view cell no 18.\n",
    "\n",
    "### PMI: degree of association between words by comparing observed co-occurrence frequency with \n",
    "### expected co-occurrence frequency if they were independent -> less relevant\n",
    "## for a specified ngram-type, return the top n n-grams concerning its PMI value\n",
    "def toppminotfiltered(ngram,n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.pmi, n):\n",
    "            pmi = finderb.score_ngram(bigram_measures.pmi, bigram[0], bigram[1])\n",
    "            rf = finderb.ngram_fd[bigram]\n",
    "            topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.pmi, n):\n",
    "            pmi = findert.score_ngram(trigram_measures.pmi, trigram[0], trigram[1], trigram[2])\n",
    "            rf = findert.ngram_fd[trigram]\n",
    "            topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.pmi, n):\n",
    "            pmi = finderf.score_ngram(fourgram_measures.pmi, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "            rf = finderf.ngram_fd[fourgram]\n",
    "            topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "### Likelihood: 10 N-grams with highest likelihood (=statistical measure indicating the strength of association between words)\n",
    "## for a specified ngram-type, return the top n n-grams concerning its likelihood ratio\n",
    "## further details: https://stackoverflow.com/questions/21165702/nltk-collocations-for-specific-words\n",
    "def toplikelihoodnotfiltered(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.likelihood_ratio, n):\n",
    "            pmi = finderb.score_ngram(bigram_measures.likelihood_ratio, bigram[0], bigram[1])\n",
    "            rf = finderb.ngram_fd[bigram]\n",
    "            topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.likelihood_ratio, n):\n",
    "            pmi = findert.score_ngram(trigram_measures.likelihood_ratio, trigram[0], trigram[1], trigram[2])\n",
    "            rf = findert.ngram_fd[trigram]\n",
    "            topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.likelihood_ratio, n):\n",
    "            pmi = finderf.score_ngram(fourgram_measures.likelihood_ratio, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "            rf = finderf.ngram_fd[fourgram]\n",
    "            topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "  \n",
    "\n",
    "### Normalized frequency: calculates and normalizes the raw frequency of an ngram, thus the appearance probability, \n",
    "## sorted first by frequency and second alphabetically [(tuple, rf value, frequency), ...]\n",
    "def topfreqnotfiltered(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.score_ngrams(bigram_measures.raw_freq)[:n]:\n",
    "            rf = finderb.ngram_fd[bigram[0]]\n",
    "            topn.append(bigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.score_ngrams(trigram_measures.raw_freq)[:n]:\n",
    "            rf = findert.ngram_fd[trigram[0]]\n",
    "            topn.append(trigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.score_ngrams(fourgram_measures.raw_freq)[:n]:\n",
    "            rf = finderf.ngram_fd[fourgram[0]]\n",
    "            topn.append(fourgram + (rf,))\n",
    "                \n",
    "    return topn\n",
    "\n",
    "\n",
    "### Print amount of ngrams\n",
    "\n",
    "def topnsummarynotfiltered(ngram, n):\n",
    "    print(\"Top \" + str(n) + ngram + \" values not filtered\\n\\nPMI:\\n\")\n",
    "    print(str(len(toppminotfiltered(ngram, n))) + \"\\n\")\n",
    "    print(\"\\n\\nLikelihoodratio:\\n\") \n",
    "    print(str(len(toplikelihoodnotfiltered(ngram, n))) + \"\\n\")           \n",
    "    print(\"\\n\\n Frequency:\\n\")         \n",
    "    print(str(len(topfreqnotfiltered(ngram, n))) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS CELL IS SIMPLY FOR THE SAKE OF ESTIMATING THE CODE'S LIMITATIONS, NO NEED TO RUN IT\n",
    "### For result of running it with n = 200: view cell no 18.\n",
    "\n",
    "#### Functions for different association measures, all of which return lists with ngrams, measure values and amount of occurences\n",
    "\n",
    "#### To estimate limitation of code: Attempt to filter out collocations with 'gibt' \n",
    "\n",
    "\n",
    "\n",
    "### PMI: degree of association between words by comparing observed co-occurrence frequency with \n",
    "### expected co-occurrence frequency if they were independent -> less relevant\n",
    "## for a specified ngram-type, return the top n n-grams concerning its PMI value\n",
    "def toppminogibt(ngram,n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.pmi, n):\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not('gibt' in bigram):\n",
    "                pmi = finderb.score_ngram(bigram_measures.pmi, bigram[0], bigram[1])\n",
    "                rf = finderb.ngram_fd[bigram]\n",
    "                topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.pmi, n):\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not ('gibt' in trigram):\n",
    "                pmi = findert.score_ngram(trigram_measures.pmi, trigram[0], trigram[1], trigram[2])\n",
    "                rf = findert.ngram_fd[trigram]\n",
    "                topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.pmi, n):\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not('gibt' in fourgram):\n",
    "                pmi = finderf.score_ngram(fourgram_measures.pmi, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                rf = finderf.ngram_fd[fourgram]\n",
    "                topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "### Likelihood: 10 N-grams with highest likelihood (=statistical measure indicating the strength of association between words)\n",
    "## for a specified ngram-type, return the top n n-grams concerning its likelihood ratio\n",
    "## further details: https://stackoverflow.com/questions/21165702/nltk-collocations-for-specific-words\n",
    "def toplikelihoodnogibt(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not('gibt' in bigram):\n",
    "                pmi = finderb.score_ngram(bigram_measures.likelihood_ratio, bigram[0], bigram[1])\n",
    "                rf = finderb.ngram_fd[bigram]\n",
    "                topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not('gibt' in trigram):\n",
    "                pmi = findert.score_ngram(trigram_measures.likelihood_ratio, trigram[0], trigram[1], trigram[2])\n",
    "                rf = findert.ngram_fd[trigram]\n",
    "                topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.likelihood_ratio, n):\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not('gibt' in fourgram):\n",
    "                pmi = finderf.score_ngram(fourgram_measures.likelihood_ratio, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                rf = finderf.ngram_fd[fourgram]\n",
    "                topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "  \n",
    "\n",
    "### Normalized frequency: calculates and normalizes the raw frequency of an ngram, thus the appearance probability, \n",
    "## sorted first by frequency and second alphabetically [(tuple, rf value, frequency), ...]\n",
    "def topfreqnogibt(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.score_ngrams(bigram_measures.raw_freq)[:n]:\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not('gibt' in bigram):\n",
    "                rf = finderb.ngram_fd[bigram[0]]\n",
    "                topn.append(bigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.score_ngrams(trigram_measures.raw_freq)[:n]:\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not('gibt' in trigram):\n",
    "                rf = findert.ngram_fd[trigram[0]]\n",
    "                topn.append(trigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.score_ngrams(fourgram_measures.raw_freq)[:n]:\n",
    "            ## entries with 'gibt' are not included\n",
    "            if not('gibt' in fourgram):\n",
    "                rf = finderf.ngram_fd[fourgram[0]]\n",
    "                topn.append(fourgram + (rf,))\n",
    "                \n",
    "    return topn\n",
    "\n",
    "\n",
    "### Print amount of ngrams\n",
    "\n",
    "def topnsummarynogibt(ngram, n):\n",
    "    print(\"Top \" + str(n) + ngram + \" values no 'gibt'\\n\\nPMI:\\n\")\n",
    "    print(str(len(toppminogibt(ngram, n))) + \"\\n\")\n",
    "    print(\"Likelihoodratio:\\n\") \n",
    "    print(str(len(toplikelihoodnogibt(ngram, n))) + \"\\n\")           \n",
    "    print(\"Frequency:\\n\")         \n",
    "    print(str(len(topfreqnogibt(ngram, n))) + \"\\n\") \n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS CELL IS SIMPLY FOR THE SAKE OF ESTIMATING THE CODE'S LIMITATIONS, NO NEED TO RUN IT\n",
    "### For result of running it with n = 200: view cell no 18.\n",
    "\n",
    "#### Functions for different association measures, all of which return lists with ngrams, measure values and amount of occurences\n",
    "\n",
    "#### To estimate limitation of code: Attempt to filter out collocations with named entities\n",
    "\n",
    "\n",
    "### PMI: degree of association between words by comparing observed co-occurrence frequency with \n",
    "### expected co-occurrence frequency if they were independent -> less relevant\n",
    "## for a specified ngram-type, return the top n n-grams concerning its PMI value\n",
    "def toppminone(ngram,n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.pmi, n):\n",
    "            ## entries with named entities are not included\n",
    "            if not(bigram in entities):\n",
    "                pmi = finderb.score_ngram(bigram_measures.pmi, bigram[0], bigram[1])\n",
    "                rf = finderb.ngram_fd[bigram]\n",
    "                topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.pmi, n):\n",
    "            ## entries with named entities are not included\n",
    "            if not (trigram in entities):\n",
    "                pmi = findert.score_ngram(trigram_measures.pmi, trigram[0], trigram[1], trigram[2])\n",
    "                rf = findert.ngram_fd[trigram]\n",
    "                topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.pmi, n):\n",
    "            ## entries with named entities are not included\n",
    "            if not(fourgram in entities):\n",
    "                pmi = finderf.score_ngram(fourgram_measures.pmi, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                rf = finderf.ngram_fd[fourgram]\n",
    "                topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "### Likelihood: 10 N-grams with highest likelihood (=statistical measure indicating the strength of association between words)\n",
    "## for a specified ngram-type, return the top n n-grams concerning its likelihood ratio\n",
    "## further details: https://stackoverflow.com/questions/21165702/nltk-collocations-for-specific-words\n",
    "def toplikelihoodnone(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.nbest(bigram_measures.likelihood_ratio, n):\n",
    "            ## entries with named entities are not included\n",
    "            if not(bigram in entities):\n",
    "                pmi = finderb.score_ngram(bigram_measures.likelihood_ratio, bigram[0], bigram[1])\n",
    "                rf = finderb.ngram_fd[bigram]\n",
    "                topn.append((bigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.likelihood_ratio, n):\n",
    "            ## entries with named entities are not included\n",
    "            if not(trigram in entities):\n",
    "                pmi = findert.score_ngram(trigram_measures.likelihood_ratio, trigram[0], trigram[1], trigram[2])\n",
    "                rf = findert.ngram_fd[trigram]\n",
    "                topn.append((trigram, pmi, rf))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.likelihood_ratio, n):\n",
    "            ## entries with named entities are not included\n",
    "            if not(fourgram in entities):\n",
    "                pmi = finderf.score_ngram(fourgram_measures.likelihood_ratio, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                rf = finderf.ngram_fd[fourgram]\n",
    "                topn.append((fourgram, pmi, rf))\n",
    "    return topn\n",
    "\n",
    "  \n",
    "\n",
    "### Normalized frequency: calculates and normalizes the raw frequency of an ngram, thus the appearance probability, \n",
    "## sorted first by frequency and second alphabetically [(tuple, rf value, frequency), ...]\n",
    "def topfreqnone(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        for bigram in finderb.score_ngrams(bigram_measures.raw_freq)[:n]:\n",
    "        ## entries with named entities are not included\n",
    "            if not(bigram in entities):\n",
    "                rf = finderb.ngram_fd[bigram[0]]\n",
    "                topn.append(bigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.score_ngrams(trigram_measures.raw_freq)[:n]:\n",
    "            ## entries with named entities are not included\n",
    "            if not(trigram in entities):\n",
    "                rf = findert.ngram_fd[trigram[0]]\n",
    "                topn.append(trigram + (rf,))\n",
    "                \n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.score_ngrams(fourgram_measures.raw_freq)[:n]:\n",
    "            ## entries with named entities are not included\n",
    "            if not(fourgram in entities):\n",
    "                rf = finderf.ngram_fd[fourgram[0]]\n",
    "                topn.append(fourgram + (rf,))\n",
    "                \n",
    "    return topn\n",
    "\n",
    "\n",
    "### Print amount of ngrams\n",
    "\n",
    "def topnsummarynone(ngram, n):\n",
    "    print(\"Top \" + str(n) + ngram + \"values no named entities \\n\\nPMI:\\n\")\n",
    "    print(str(len(toppminone(ngram, n))) + \"\\n\")\n",
    "    print(\"Likelihoodratio:\\n\") \n",
    "    print(str(len(toplikelihoodnone(ngram, n))) + \"\\n\")           \n",
    "    print(\"Frequency:\\n\")         \n",
    "    print(str(len(topfreqnone(ngram, n))) + \"\\n\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### proposal: to make len(list of ngrams) = n -> \"while\" loop that continues appending until len(topn) = n\n",
    "### didn't work (didn't find end of loop, maybe the intial search set should have been set differently)\n",
    "### but this was the idea for the function as used on the likelihood function, could be used analogically for the others:\n",
    "def toplikelihood(ngram, n):\n",
    "    topn = []\n",
    "    if (ngram == \"bigram\"):\n",
    "        ### take the top 4*n entries as set to search in for, so that you can fill up the topn even if there are a lot of ngrams with 'gibt' and named entities\n",
    "         for bigram in finderb.nbest(bigram_measures.likelihood_ratio, 4 * n):\n",
    "            while(len(topn) != n):\n",
    "                ## entries with 'gibt' and named entities are not included\n",
    "                if not(('gibt' in bigram) or (bigram in entities)):\n",
    "                    pmi = finderb.score_ngram(bigram_measures.likelihood_ratio, bigram[0], bigram[1])\n",
    "                    rf = finderb.ngram_fd[bigram]\n",
    "                    topn.append((bigram, pmi, rf))\n",
    "            return topn\n",
    "    if (ngram == \"trigram\"):\n",
    "        for trigram in findert.nbest(trigram_measures.likelihood_ratio, 4 * n):\n",
    "            ### take the top 4*n entries as set to search in for, so that you can fill up the topn even if there are a lot of ngrams with 'gibt' and named entities\n",
    "            while(len(topn) != n):\n",
    "                ## entries with 'gibt' and named entities are not included\n",
    "                if not(('gibt' in trigram) or (trigram in entities)):\n",
    "                    pmi = findert.score_ngram(trigram_measures.likelihood_ratio, trigram[0], trigram[1], trigram[2])\n",
    "                    rf = findert.ngram_fd[trigram]\n",
    "                    topn.append((trigram, pmi, rf))\n",
    "            return topn\n",
    "    if (ngram == \"fourgram\"):\n",
    "        for fourgram in finderf.nbest(fourgram_measures.likelihood_ratio, 4 * n):\n",
    "            ### take the top 4*n entries as set to search in for, so that you can fill up the topn even if there are a lot of ngrams with 'gibt' and named entities\n",
    "            while(len(topn) != n):\n",
    "                ## entries with 'gibt' and named entities are not included\n",
    "                if not (('gibt' in fourgram) or (fourgram in entities)):\n",
    "                    pmi = finderf.score_ngram(fourgram_measures.likelihood_ratio, fourgram[0], fourgram[1], fourgram[2], fourgram[3])\n",
    "                    rf = finderf.ngram_fd[fourgram]\n",
    "                    topn.append((fourgram, pmi, rf))  \n",
    "        return topn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstration of why it was useful to filter out some collocations with 'gibt', \n",
    "## -> many entries include 'gibt' but don't vary in terms of used grammar\n",
    "findert.nbest(trigram_measures.likelihood_ratio, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tests:\n",
    "## for all relevant functions (without \"gibt\" and named entities), sorted by ngrams, Top 10), \n",
    "## Likelihoodratio is empty for Trigrams and Fourgrams because top entries all included 'gibt' or named entities\n",
    "\n",
    "### Bigrams\n",
    "print(\"\\n PMI:\\n\")\n",
    "print(toppmi(\"bigram\", 10))\n",
    "print(\"\\n Likelihoodratio:\\n\")\n",
    "print(toplikelihood(\"bigram\", 10))\n",
    "print(\"\\n Frequency \\n\")\n",
    "print(topfreq(\"bigram\", 10))\n",
    "\n",
    "### Trigrams\n",
    "print(\"\\n PMI:\\n\")\n",
    "print(toppmi(\"trigram\", 10))\n",
    "print(\"\\n Likelihoodratio:\\n\")\n",
    "print(toplikelihood(\"trigram\", 10))\n",
    "print(\"\\n Frequency \\n\")\n",
    "print(topfreq(\"trigram\", 10))\n",
    "\n",
    "### Fourgrams\n",
    "print(\"\\n PMI:\\n\")\n",
    "print(toppmi(\"fourgram\", 10))\n",
    "print(\"\\n Likelihoodratio:\\n\")\n",
    "print(toplikelihood(\"fourgram\", 10))\n",
    "print(\"\\n Frequency \\n\")\n",
    "print(topfreq(\"fourgram\", 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8272f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR THE SAKE OF COMPARISON: produce all the different versione \n",
    "# (nothing filtered out, gibt filtered out, named entities filtered out, both filtered out)\n",
    "### and compare amount of result to view how well the recognition and filtering works\n",
    "\n",
    "### Amount of ngrams, nothing filtered:\n",
    "topnsummarynotfiltered(\"bigram\", 200)\n",
    "topnsummarynotfiltered(\"trigram\", 200)\n",
    "topnsummarynotfiltered(\"fourgram\", 200)\n",
    "\n",
    "### Amount of ngrams, 'gibt' filtered out:\n",
    "topnsummarynogibt(\"bigram\", 200)\n",
    "topnsummarynogibt(\"trigram\", 200)\n",
    "topnsummarynogibt(\"fourgram\", 200)\n",
    "\n",
    "### Amount of ngrams, named entities filtered out:\n",
    "topnsummarynone(\"bigram\", 200)\n",
    "topnsummarynone(\"trigram\", 200)\n",
    "topnsummarynone(\"fourgram\", 200)\n",
    "\n",
    "### Amount of ngrams, both 'gibt' and named entities filtered out\n",
    "printsummary(\"bigram\", 200)\n",
    "printsummary(\"trigram\", 200)\n",
    "printsummary(\"fourgram\", 200)\n",
    "\n",
    "\n",
    "### Results:\n",
    "## For 'gibt', the code filtered out: \n",
    "# 2 bigrams in Likelihood\n",
    "# 119 trigrams in Likelihood\n",
    "# 3 fourgrams in PMI \n",
    "# 79 fourgrams in likelihood\n",
    "\n",
    "# For Named Entities, the code filtered out:\n",
    "# 58 bigrams in PMI\n",
    "# 7 bigrams in Likelihood\n",
    "# 11 trigrams in PMI\n",
    "# 2 fourgrams in PMI\n",
    "\n",
    "## In topnsummary, the code filtered out (-> corresponds to [filtered out 'gibt'] + [filtered out NE]?):\n",
    "# 58 bigrams in PMI -> corresponds to 58 + 0!\n",
    "# 9 bigrams in Likelihood  -> corresponds to 2 + 7!\n",
    "# 11 trigrams in PMI -> corresponds to 0 + 11!\n",
    "# 119 trigrams in Likelihood -> corresponds to 119 + 0!\n",
    "# 5 fourgrams in PMI -> corresponds to 3 + 2!\n",
    "# 79 fourgrams in Likelihood -> corresponds to 0 + 79!\n",
    "\n",
    "\n",
    "## Thus, the code filtered out 67 bigrams, 130 trigrams, and 84 fourgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use to view top n summary here instead of having to open the text files:\n",
    "\n",
    "## Top 200 Bigrams: \n",
    "print(\"\\n Top 200 Bigrams without gibt and Named Entities\\n\")\n",
    "topnsummary(\"bigram\", 200)\n",
    "with open('top200bigrams.txt', encoding = 'utf-8') as text:\n",
    "    print(text.read())\n",
    "\n",
    "\n",
    "## Top 200 Trigrams:\n",
    "print(\"\\n Top 200 Trigrams without gibt and Named Entities\\n\")\n",
    "topnsummary(\"trigram\", 200)\n",
    "with open('top200trigrams.txt', encoding = 'utf-8') as text:\n",
    "    print(text.read())\n",
    "    \n",
    "## Top 200 Fourgrams:\n",
    "print(\"\\n Top 200 Fourgrams without gibt and Named Entities\\n\") \n",
    "topnsummary(\"fourgram\", 200)\n",
    "with open('top200fourgrams.txt', encoding = 'utf-8') as text:\n",
    "    print(text.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff3b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for looking at specific Named Entities, e.g. all locations\n",
    "\n",
    "for e in set(doc.ents): \n",
    "    if (e.label_ == 'LOC'): \n",
    "        print(e.text) \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
